{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 3, Lab 3 - Causal Claims\n",
    "===============================\n",
    "\n",
    "In this lab, we briefly explore the causal claim. Recall that if you\n",
    "want to truly understand your variables, you want to draw cause-effect\n",
    "conclusions. Association claims are useful; they let you know what\n",
    "variables correlate with each other.\n",
    "\n",
    "In this lab, we will use the `effsize` package for measuring effect size\n",
    "and the `ggplot2` package for data visualization. We will also briefly\n",
    "explore the `ggridges` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD PACKAGES ####\n",
    "from scipy import stats\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.stats.weightstats as ws\n",
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weaknesses of Association Claims for Deep Understanding\n",
    "========================================================\n",
    "\n",
    "However, they don't tell you what will happen if you intervene and act\n",
    "in the world in new ways. For example, imagine you have been analyzing\n",
    "data at your organization and find that employees who are less stressed\n",
    "tend to be more productive. It may be very unclear *why* that\n",
    "relationship exists. Some possibilities include:\n",
    "\n",
    "1.  Stress reduces productivity\n",
    "2.  Productivity reduces stress\n",
    "3.  Some other variable is causing both of them\n",
    "\n",
    "It is worth putting real thought into all of these.\n",
    "\n",
    "1.  For example, it is reasonable that stress reduces productivity.\n",
    "2.  However, it is also reasonable that getting things done may take\n",
    "    stress off of the shoulders of employees as they clear projects off\n",
    "    their to-do lists.\n",
    "3.  It is also possible that something else may be casing both high\n",
    "    stress and low productivity, such as obligations outside of work,\n",
    "    health issues, etc.\n",
    "\n",
    "All three of these have different implications for how to increase\n",
    "productivity:\n",
    "\n",
    "1.  The first possibility suggests that reducing stress might actually\n",
    "    help.\n",
    "2.  The second possibility suggests that reducing stress will not help\n",
    "    (but finding other contributors to productivity might, so we should\n",
    "    go looking for those). Time for more research!\n",
    "3.  The third possibility suggests that attempts to reduce stress would\n",
    "    do nothing to increase productivity because the real problem is the\n",
    "    unmeasured *prior cause* of the stress. For example, if health\n",
    "    issues are causing people to be more stressed and less productive,\n",
    "    then the desired boost to productivity will not come from reducing\n",
    "    stress but from fixing the underlying health issues.\n",
    "\n",
    "In conclusion, association claims are limited in their ability to help\n",
    "you draw cause-effect conclusions. Or, to put it differently, we could\n",
    "*predict* the productivity of an employee given their stress levels, but\n",
    "we wouldn't know how to actually *improve* productivity given this\n",
    "information. Association claims simply don't really tell you what is\n",
    "causing what.\n",
    "\n",
    "Solution: The Experiment\n",
    "========================\n",
    "\n",
    "To solve this problem, we run an experiment. Imagine we randomly assign\n",
    "250 employees to a stress-reduction treatment or a \"business-as-usual\"\n",
    "control group. After 7 weeks, the productivity of these employees is\n",
    "assessed.\n",
    "\n",
    "Because employees are *randomly* assigned to groups *by the researcher*,\n",
    "the research can be confident that\n",
    "\n",
    "-   The two groups were approximately equal to begin with (this can be\n",
    "    checked, if desired)\n",
    "-   Any differences at the end of the study are due to the treatment\n",
    "\n",
    "We can draw this conclusion because we will be very careful to treat the\n",
    "groups *identically* in every way, except for the treatment. We must be\n",
    "**exceedingly** careful on this point, as any unintended differences in\n",
    "treatment (the messaging we give them, the scheduling, workload, etc.)\n",
    "could accidentally cause a second systematic difference between our\n",
    "groups, and then we would not be sure what was really responsible for\n",
    "any effects we end up seeing. This is known as a *confound* and it would\n",
    "run our experiment. We will be very sure not to allow this to happen,\n",
    "using strict protocols, scripts, email templates, etc. We would be very\n",
    "careful to manage expectations so neither group had different\n",
    "expectations (possibly keeping our employees blind to some of the\n",
    "details, or keeping managers in the dark). Our goal will be to keep\n",
    "**everything the same between our groups**, tangibly and mentally,\n",
    "except for the actual treatment itself. This will take very detailed and\n",
    "rigorous planning, but it is worth it. A small-scale pilot of an\n",
    "intervention program will take some rigorous planning, but it is much\n",
    "less expensive than rolling out a company-wide stress program only to\n",
    "find it is a waste of money and ineffective (as might happen in many\n",
    "organizations).\n",
    "\n",
    "Analyzing the Experiment\n",
    "========================\n",
    "\n",
    "To analyze the experiment, a simple independent-groups *t*-test can be\n",
    "performed. This compares the means of the two groups to determine if\n",
    "they are statistically significantly different.\n",
    "\n",
    "Imagine the study is done; the data are called \"causal.csv\" and are in\n",
    "the github folder for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'group', 'prod'], dtype='object')\n",
      "\n",
      "\n",
      "   Unnamed: 0         group  prod\n",
      "0         261       control  3.44\n",
      "1         168  intervention  3.26\n",
      "2         498       control  4.26\n",
      "3         447       control  4.53\n",
      "4          64  intervention  5.92\n",
      "\n",
      "\n",
      "['control' 'intervention']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>4.160080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "      <td>1.006379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.750000</td>\n",
       "      <td>3.522500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>4.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.250000</td>\n",
       "      <td>4.817500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>7.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        prod\n",
       "count  500.000000  500.000000\n",
       "mean   250.500000    4.160080\n",
       "std    144.481833    1.006379\n",
       "min      1.000000    0.700000\n",
       "25%    125.750000    3.522500\n",
       "50%    250.500000    4.120000\n",
       "75%    375.250000    4.817500\n",
       "max    500.000000    7.850000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### LOAD DATA ####\n",
    "import pandas as pd\n",
    "dat = pd.read_csv(\"datasets/causal.csv\")\n",
    "\n",
    "# Inspect data\n",
    "print(dat.columns)\n",
    "\n",
    "print('\\n')\n",
    "print(dat.head())\n",
    "\n",
    "print('\\n')\n",
    "print(dat.group.unique())\n",
    "\n",
    "dat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see we have three variables, an unnamed id variable, a variable\n",
    "listing the group, and the productivity scores of the employees on a 1-7\n",
    "scale. We want to compare the two groups, and we can do so by looking at\n",
    "the means.\n",
    "\n",
    "We can quickly request more detailed statistics. The values of `prod` can be grouped by the `group` using the Pandas `groupby` method. The mean of each group is then computed. The same recipe can be used to compute the standard deviation of the groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[['group','prod']].groupby('group').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[['group','prod']].groupby('group').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that intervention group has a slightly higher average\n",
    "productivity score. We can next test the null hypothesis to see if this\n",
    "difference is significant.\n",
    "\n",
    "Recall that the null hypothesis always says that the **effect is absent\n",
    "in the population** and that the sample result is an artifact of random\n",
    "chance. In symbols, this means that the difference between the group\n",
    "averages is exactly zero in the population.\n",
    "\n",
    "*H*<sub>0</sub> : *μ*<sub>*g**r**o**u**p*1</sub> − *μ*<sub>*g**r**o**u**p*2</sub> = 0\n",
    " Remember that *μ* refers to the population average, so this is saying\n",
    "that the population difference is exactly zero. Any difference observed\n",
    "in our sample is therefore due to random chance. We run our *t*-test to\n",
    "consider this possibility.\n",
    "\n",
    "Recall that a *t*-test compares the size of the *observed difference*\n",
    "($\\bar{x}_{1} - \\bar{x}_{2}$) against the value in the null hypothesis\n",
    "(zero), divided by what is typically expected by chance:\n",
    "\n",
    "$$t= \\frac{result - null }{chance}$$\n",
    " For the two-group *t*-test, the \"result\" is the difference between the\n",
    "group averages in the sample, the \"null\" states the difference, and\n",
    "\"chance\" is the standard error of that difference.\n",
    "\n",
    "How can we run our test? The default in R is to run the \"Welch\" version\n",
    "of the test. This version of the test does *not* make any assumptions\n",
    "about the variances of the two groups.\n",
    "\n",
    "$$t'= \\frac{result - null }{chance}= \\frac{(\\bar{x}_{1}-\\bar{x}_{2}) - 0 }{\\sqrt{\\frac{\\hat{\\sigma}_1^2}{n_{1}}+\\frac{\\hat{\\sigma}_2^2}{n_{2}}}}$$\n",
    " The bottom looks complicated but is simply a measure of the standard\n",
    "error of the size of the difference between our two groups. We can\n",
    "explore the details of this equation in a later lab. For now, let's run\n",
    "the test and interpret the result.\n",
    "\n",
    "The Python code in the function below does the following:\n",
    "1. Compute the difference of means. \n",
    "2. The `ttest_ind` function from the scipy.stats package to compute the t statistic and p-value.\n",
    "3. The `tconfint_diff` function is used to compute the confidence interval.\n",
    "4. The `dof_satt` function estimates the degrees of freedom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_two_samp(df, alpha, alternative='two-sided'):\n",
    "    \n",
    "    a = df[df.group == 'control']['prod']\n",
    "    b = df[df.group == 'intervention']['prod']    \n",
    "    \n",
    "    diff = a.mean() - b.mean()\n",
    "\n",
    "    res = ss.ttest_ind(a, b)\n",
    "      \n",
    "    means = ws.CompareMeans(ws.DescrStatsW(a), ws.DescrStatsW(b))\n",
    "    confint = means.tconfint_diff(alpha=alpha, alternative=alternative, usevar='unequal') \n",
    "    degfree = means.dof_satt()\n",
    "\n",
    "    index = ['DegFreedom', 'Difference', 'Statistic', 'PValue', 'Low95CI', 'High95CI']\n",
    "    return pd.Series([degfree, diff, res[0], res[1], confint[0], confint[1]], index = index)   \n",
    "   \n",
    "\n",
    "test = t_test_two_samp(dat, 0.05)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *t*-value of 3.16 tells us that the difference between our groups\n",
    "(top of *t*-test fraction) is 3.16 times larger than would be expected\n",
    "typically by chance (bottom of *t*-test fraction). How often would a\n",
    "result this big happen if the null were actually true? The *p*-value is\n",
    ".002, so only 0.2% of the time. This is sufficient to reject the null\n",
    "(*p* &lt; .05), and we can conclude that our difference is not due to\n",
    "chance. We also have a 95% CI on the size of the difference, and we are\n",
    "fairly confident that the control group is .457 to 0.107 productivity\n",
    "points lower than intervention group.\n",
    "\n",
    "Importantly, because we performed a randomized, controlled experiment,\n",
    "we can conclude that this was actually the result of our treatment. This\n",
    "is a good sign, but the size of the improvement is small. We can\n",
    "conclude that our intervention **did** improve productivity, but it was\n",
    "only by about a quarter of a point.\n",
    "\n",
    "How big is that? Well, the scale is a 1-7 scale. We can try plotting the data using a boxplot of the two groups to visualize it. The Seaborn code in the cell below creates a boxplot of the `prod` values grouped by the `group` variable. A `swarmplot` is superimposed so you can see the position of the data points. The swarm plot shows a jittered display of the data points.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(8,8)).gca() # define axis\n",
    "sns.boxplot(x = 'group', y = 'prod', data = dat, ax = ax)\n",
    "sns.swarmplot(x = 'group', y = 'prod', color = 'black', data = dat, ax = ax, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](M3_Lab3_-_Causal_Claim_files/figure-markdown_strict/unnamed-chunk-5-1.png)\n",
    "\n",
    "A violin plot might also help to visualize the differences. The code in the cell below follows the same recipe used above, but with the `violinplot` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(8,8)).gca() # define axis\n",
    "sns.violinplot(x = 'group', y = 'prod', data = dat, ax = ax)\n",
    "sns.swarmplot(x = 'group', y = 'prod', color = 'black', data = dat, ax = ax, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](M3_Lab3_-_Causal_Claim_files/figure-markdown_strict/unnamed-chunk-7-1.png)\n",
    "\n",
    "We see from the above plots that, although the effect was statistically significant, the\n",
    "difference is fairly minimal.\n",
    "\n",
    "We can estimate our effect size (Cohen's *d*) using the `tt_ind_solve_power`\n",
    "function from the `statsmodels.stats.power` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cohen.d(prod ~ group, data=dat)\n",
    "control = dat[dat.group == 'control']['prod']\n",
    "intervention = dat[dat.group == 'intervention']['prod']\n",
    "print(np.mean(intervention) - np.mean(control))\n",
    "ratio = len(control)/len(intervention)\n",
    "tt_ind_solve_power(effect_size=None, nobs1 = len(control), alpha=0.05, power=0.8, ratio=ratio, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results you can see that the actual difference between these groups is a bit larger than Cohen's d required from 0.80 power.\n",
    "\n",
    "Conclusion\n",
    "==========\n",
    "\n",
    "Thanks to this study, we can be fairly certain that the stress reduction\n",
    "intervention had an effect. However, the difference in the effect is\n",
    "minimal at best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
