{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 2, Lab 1 - Sampling\n",
    "==========================\n",
    "\n",
    "In this lab, we will see how random samples (and the data analyses that\n",
    "come from them) estimate the populations they come from.\n",
    "\n",
    "This bears repeating: when you are working with a sample of data, you\n",
    "are using that as an estimate of the population that generated it.\n",
    "\n",
    "So, how good are your estimations? In working with professionals and\n",
    "students alike, I tend to find that our human intuitions are often\n",
    "wrong. However, we can play with sampling ourselves and see the results.\n",
    "\n",
    "First, we should set the seed. A seed is set using the `seed` function from the Numpy.random Python package. This function initializes the random number generation on your computer as mine, so that we should get the same\n",
    "results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as nr\n",
    "nr.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a random sample that is normally distributed, we use the\n",
    "`normal(mean, std, n)`. For example, 50 responses from a population with a\n",
    "mean of 10 and standard deviation of 2 are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.59058468, 10.95788668,  8.96112257,  8.88853939, 13.93156115,\n",
       "       12.78681167, 10.18581575, 10.56349231, 11.53804514, 12.49286947,\n",
       "       12.01437872,  7.40755778, 10.54998327, 10.45782576, 12.70583367,\n",
       "       11.77285868,  5.99672538,  9.25631493, 13.33805062,  9.12286053,\n",
       "        8.92051711, 10.95397002, 16.49788784,  7.95754495,  8.84582539,\n",
       "       10.24824255, 10.60522712, 11.04754414, 10.00188056, 12.68761959,\n",
       "        8.57291203,  8.33769292,  5.25953669,  6.27847842,  8.2784852 ,\n",
       "       11.12029059,  7.46813102, 10.23965425,  7.8729751 , 10.66576543,\n",
       "        5.28116239,  9.60091409,  6.91600894,  8.05852818,  7.3859395 ,\n",
       "       10.57269949, 10.75596822,  8.49222693, 10.6625713 , 12.69948443])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.normal(10, 2, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Numpy array with the Normally distributed values is returned. \n",
    "\n",
    "We can also do something similar with a binomial distribution (data can\n",
    "have two outcomes, such as \"like\" and \"don't like\" a product). Here is\n",
    "the code which uses: `binomial(n, prob, size=1)`. The `prob` argument represents\n",
    "the likelihood of getting a `1` as opposed to a `0`. The size argument\n",
    "changes the nature of the distribution in a way I won't discuss here. If\n",
    "we want to simulate 50 responses from a population in which 30% of\n",
    "people like your product (`1`) and 70% do not (`0`), we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(3344)\n",
    "nr.binomial(1, 0.3, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, each `1` represents someone who likes your product and\n",
    "each `0` represents someone who does not.\n",
    "\n",
    "There are many distributions we can use with many shapes, including\n",
    "distributions that have skew, distributions that can resemble counts of\n",
    "things (e.g., only discrete numbers, most scores zero). We will stick\n",
    "with these two for this lab.\n",
    "\n",
    "\"Like\" vs \"Dislike\"\n",
    "===================\n",
    "\n",
    "Let's try the example above in which each `1` represents someone who\n",
    "likes your product and each `0` represents someone who does not.\n",
    "\n",
    "This time, I will run the sample and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(3344)\n",
    "sample1 = nr.binomial(1, 0.3, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can examine how well our sample did. In this case we *know* the population value was 30%, because we specified that parameter when we ran the code. How close did it get to our true value of 30%? To answer this question execute the `itemfreq` function from the `scipy.stats` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 37]\n",
      " [ 1 13]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "print(stats.itemfreq(sample1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 likes and 37 dislikes. We can convert to\n",
    "percentages by diving by the sum of likes and dislikes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13.0/(13.0 + 37.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our sample underestimated the number of people who like the product,\n",
    "returning \"26%\" instead of 30%.\n",
    "\n",
    "Because the data are coded `0` and `1`, we can also trick the math into\n",
    "returning a proportion by using `mean()` from Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(sample1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this several times. Every time I run the code, a random sample\n",
    "will be collected, the proportion of people who like the product\n",
    "calculated, and reported to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(nr.binomial(1, 0.3, 50)))\n",
    "print(np.mean(nr.binomial(1, 0.3, 50)))\n",
    "print(np.mean(nr.binomial(1, 0.3, 50)))\n",
    "print(np.mean(nr.binomial(1, 0.3, 50)))\n",
    "print(np.mean(nr.binomial(1, 0.3, 50)))\n",
    "print(np.mean(nr.binomial(1, 0.3, 50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that our samples are varying quite a bit. We can run many of\n",
    "these by using a list comprehension. Let's try this 100 times. I assume you are\n",
    "familiar with loops in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [np.mean(nr.binomial(1, 0.3, 50)) for _ in range(100)]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see considerable variance in these results. We can histogram them to\n",
    "see it better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the plot appears in line in the noteboook\n",
    "%matplotlib inline \n",
    "\n",
    "sample_mean = np.mean(results)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(results)\n",
    "plt.vlines(0.3, 0.0, 28.0, color = 'red')\n",
    "plt.vlines(sample_mean, 0.0, 28.0, color = 'black')\n",
    "plt.xlabel('Results') \n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that, on average, random samples are trustworthy--after all,\n",
    "they are tending toward 30%. However, *individual* samples are\n",
    "less trustworthy. Some results are nearly as large as 135% or as low as\n",
    "50%. Yikes!\n",
    "\n",
    "We can also subtract .30 from each score to re-score them as the degree\n",
    "of error in each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_error = [round(x - 0.3, 2) for x in results]\n",
    "print(results_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that most sample scores are within about 5% of the true\n",
    "population value value. Still, depending on what we want to do with the\n",
    "data, that could be unacceptably large. The property of samples to\n",
    "\"mis-estimate\" the population is called sampling error and it is clearly\n",
    "a big problem, leading to many a bad decision. The degree to which your\n",
    "individual samples tend to \"mis-estimate\" the population (shown above:\n",
    "`results_error`) is something we want to estimate. Typically, we\n",
    "quantify this by taking the standard deviation of these errors. This is\n",
    "called \"standard error\", and it is a single number, how far \"off\" our\n",
    "samples tend to be, on average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(results_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha, so we see that the average sample is \"off\" from the population\n",
    "value by 6%. Some are \"off\" by more; some are \"off\" by less, but the\n",
    "average sample is off by 6%. In other words, our standard error is 6%.\n",
    "\n",
    "Fun fact: you can also estimate the standard error with a simple\n",
    "equation. For binomial data (`0` and `1` scores), the equation is:\n",
    "\n",
    "$$se = \\sqrt{\\frac{p\\left ( 1-p \\right )}{n-1}}$$\n",
    " Here, p is the percentage in the population. So, plugging in our\n",
    "values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt((.30*(1-.3))/(50-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is convenient, because it tells us that we don't really need to run\n",
    "simulations like the above to know how trustworthy our samples are. In\n",
    "fact, plugging in a reasonable guess for the population value and a\n",
    "sample size, we can know *before we run a study* how trustworthy a\n",
    "typical sample will be.\n",
    "\n",
    "Clearly, a large standard error is a bad thing. We can reduce this\n",
    "problem by relying on a larger sample. For example, try using a sample\n",
    "of 700 in the equation for standard error shown previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt((.30*(1-.3))/(700-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now that the typical sample will be off by only 1.7% from the\n",
    "population value. We can run a similar loop as done before and see this\n",
    "in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [np.mean(nr.binomial(1, 0.3, 700)) for _ in range(100)]\n",
    "\n",
    "print(np.std(results))\n",
    "\n",
    "sample_mean = np.mean(results)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(results)\n",
    "plt.vlines(0.3, 0.0, 28.0, color = 'red')\n",
    "plt.vlines(sample_mean, 0.0, 28.0, color = 'black')\n",
    "plt.xlabel('Results') \n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here, now that most results between 82% and 112%, with the typical\n",
    "result being \"off\" by only 1.7%...exactly as our standard error equation\n",
    "predicted.\n",
    "\n",
    "Every data situation has a standard error. The point is not to learn a\n",
    "large number of equations but rather to emphasize the following point:\n",
    "samples (and the statistics they produce) are flawed estimates of the\n",
    "population. However, they become more and more accurate as the sample\n",
    "sizes they are based on increase.\n",
    "\n",
    "We will discover, soon, that this will give us the concept of\n",
    "statistical power. Large samples will produce results strong enough that\n",
    "we can make meaningful statements about the population (in such\n",
    "situations, we have \"good power\"), where small samples contain so much\n",
    "error that we cannot say much meaningful about the population (\"weak\n",
    "power\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
