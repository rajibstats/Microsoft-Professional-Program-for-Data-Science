{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 2, Lab 2: *p*-values\n",
    "===========================\n",
    "\n",
    "In this lab, we will explore how the basics of null hypothesis\n",
    "significance testing work. Although you may have examined this in a\n",
    "previous course, we will review the concepts of *p*-values and tests of\n",
    "statistical significance with an emphasis on their application in\n",
    "research.\n",
    "\n",
    "The Null Hypothesis\n",
    "===================\n",
    "\n",
    "First, we briefly review what the null hypothesis is. Recall from the\n",
    "previous lab that the results that come from samples are only mere\n",
    "estimates of the population. Because they are estimates, the statistics\n",
    "they produce will differ somewhat from their population counterparts.\n",
    "For example, the correlation between engagement in a sample may be *r* =\n",
    ".2 even when the correlation between those same variables in the\n",
    "population is something smaller, such as .10 or even 0. This can cause\n",
    "apparent relationships and effects to appear in *samples* when none in\n",
    "fact exists in the population. This idea--that the effect/association is\n",
    "*zero* in the population--is called the null hypothesis. By implication,\n",
    "any effect/association seen in the *sample* must be entirely due to the\n",
    "random chance of \"sampling error.\" In other words, the null hypothesis\n",
    "claims that the sample result is a random fluke.\n",
    "\n",
    "Let's explore an application of this. Imagine we want to compare males\n",
    "and females in terms of their interest in a given product. Imagine, for\n",
    "a moment, that *the two groups have identical interest* (in the\n",
    "population)...that is, there is no difference between the groups.\n",
    "Nevertheless, if we take a sample of males and a sample of females, the\n",
    "error in our estimations will cause a difference to appear.\n",
    "\n",
    "Imagine that *both* males and females had an interest level averaging at\n",
    "5, with a standard deviation of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to make random number generation reproducible\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "nr.seed(515212)\n",
    "\n",
    "#collect a sample of 100 males\n",
    "males = nr.normal(5, 3, 100)\n",
    "\n",
    "#collect a sample of 100 females\n",
    "females = nr.normal(5, 3, 100)\n",
    "\n",
    "print(np.mean(males))\n",
    "print(np.mean(females))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that our two groups have different sample results. Let's see\n",
    "how large the difference is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(males)-np.mean(females)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the females are almost 1/2 of a point higher than the\n",
    "males. If you saw this data in an organization where you were working,\n",
    "you might be tempted to think you'd discovered a female preference for\n",
    "your product. However, in fact, we *know* in this case that this is\n",
    "nonsense as we *know* (because we wrote the Python code simulating this data)\n",
    "that *both* groups were random samples from a population with a mean of\n",
    "5 and a standard deviation of 3. If their means are both 5.0 (exactly)\n",
    "in the population, why did the females score higher in the samples? It's\n",
    "simple: sampling error. That is, the difference is **entirely** due to\n",
    "random error in the samples, not any real difference in the population.\n",
    "We have discovered a fluke in some sample data, nothing more.\n",
    "\n",
    "This is a case of the \"null hypothesis.\" In this case, the means are\n",
    "*equal* in the population. We write the null hypothesis as\n",
    "*H*<sub>0</sub> and it is always a statement that the size of the effect\n",
    "in the population is zero. In this case, we are testing the difference\n",
    "between the averages ($\\mu ' s$), stating that the *difference between\n",
    "them is zero*:\n",
    "\n",
    "$$H_0 :\\ \\mu_{male} - \\mu_{female} = 0$$\n",
    "\n",
    "However, to reiterate what we saw above, *when we looked at our\n",
    "samples,* we saw there was a difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(males)-np.mean(females)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in conclusion, the null hypothesis says that whatever effect you are\n",
    "studying is *zero* in the population and *your sample results are due to\n",
    "random chance.*\n",
    "\n",
    "This possibility looms ominously over every research finding based on\n",
    "samples data. How do we know that the effects we trust every day (the\n",
    "effect of medicine, tested leadership practices, etc.) are real and not\n",
    "just flukes due to random sampling error? We need to find a way to test\n",
    "the null hypothesis and see if we can reject this possibility.\n",
    "\n",
    "Null Hypothesis Significance Test: The *p*-Value\n",
    "================================================\n",
    "\n",
    "To test the null hypothesis, we simply ask: *if the null hypothesis were\n",
    "true, what percentage of the time would I get this result this large?*\n",
    "The answer to that question is called a *p*-value.\n",
    "\n",
    "There is a lot of confusion about *p*-values, so let's review:\n",
    "\n",
    "-   *p*-values represent how often you could get a result as big as you\n",
    "    did *if the null were true*\n",
    "-   *p*-values therefore represent how easy/hard it would be to get a\n",
    "    result by chance\n",
    "-   *p*-values do **not** tell you the probability that the result is\n",
    "    due to chance; only the probability of seeing *your result* if the\n",
    "    null were true\n",
    "-   If the *p*-value for a result is small, it would be rare to get that\n",
    "    result by chance (i.e., if the null were true)\n",
    "-   If the *p*-value for a result is large, it would be common to get\n",
    "    that result by chance (i.e., if the null were true)\n",
    "-   Conclusion: the *p*-value is a measure of \"incompatibility\" between\n",
    "    your result and the null. If the *p*-value is small, one of the two\n",
    "    (the data, or the null) is likely wrong. We opt to trust our data\n",
    "    and reject the null.\n",
    "\n",
    "To be clear: the *p*-value is a backwards way of testing the null\n",
    "hypothesis. We would love to know the *probability* that the null\n",
    "hypothesis is true--the probability that the results *are* due to\n",
    "chance--but we cannot know that. You will often hear the *p*-value\n",
    "described this way, but that is **very wrong**.\n",
    "\n",
    "So, to repeat, the *p-value states the probability of getting **your\n",
    "result** if the null is true*. It is essentially a statement of\n",
    "incompatibility between your data and the null. A small *p*-value\n",
    "(typically, less than 5% or \"&lt; . 05\") tells you that the data and\n",
    "null are highly incompatible. Since you did in fact observe the data,\n",
    "you conclude the null hypothesis is false. This is the only use for the\n",
    "*p*-value.\n",
    "\n",
    "Where do *p*-Values Come From?\n",
    "==============================\n",
    "\n",
    "Where does a *p*-value come from? Every data situation is different, but\n",
    "the process in so-called \"frequentist\" statistics is always the same\"\"\n",
    "\n",
    "1.  Observe data and examine result\n",
    "2.  Compute the appropriate \"test statistic\" for that result (e.g., *t*\n",
    "    test, *z* test, *χ*<sup>2</sup> test, *F* test, *q* test etc.).\n",
    "3.  Observe how often you could get the observed test statistic if the\n",
    "    null hypothesis was true. This is the *p*-value\n",
    "4.  If the *p*-value is less than .05, declare the result \"significant\"\n",
    "    and reject the null hypothesis\n",
    "\n",
    "Let's see this in action. For this example, I will use a \"one-sample\n",
    "*t*-test\", as the math is easier.\n",
    "\n",
    "Imagine we assess people's impressions of a training given in an\n",
    "organization. We assess attitudes toward the training on a -5 (very\n",
    "negative) to +5 (very positive) scale (zero = neutral opinion).\n",
    "\n",
    "The question is whether people have a positive or negative attitude\n",
    "toward the training, on average. Let's imagine that they actually have a\n",
    "positive attitude, that in the population the mean is really 2.4 (i.e.,\n",
    "*μ* = 2.4) with a standard deviation of 2.0. This is a simulated example\n",
    "(in real life, you would have no idea what the population value is:\n",
    "that's why you're doing research). Still, by showing you a simulated\n",
    "example, we can see how the procedure works.\n",
    "\n",
    "What would the null hypothesis be, here? Well, the null hypothesis\n",
    "always states that the effect is absent. In this case, an \"effect\" would\n",
    "be a non-zero attitude. Thus, in this case, *H*<sub>0</sub> : *μ* = 0.\n",
    "\n",
    "Let's pull a random sample of 100 scores from that population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(4455)\n",
    "attitude = nr.normal(2.4, 2.0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the mean and SD in our sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(attitude))\n",
    "\n",
    "print(np.std(attitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, our null hypothesis is that the mean is zero\n",
    "(*H*<sub>0</sub> : *μ* = 0) but our sample result disagrees with that\n",
    "(sample mean = 2.23).\n",
    "\n",
    "Does this *sample* gives us enough evidence to reject the null?\n",
    "\n",
    "To answer that question, we calculate a test statistic. In this case\n",
    "(one group, sample mean), we conduct a one-group *t*-test for means. (As\n",
    "you progress in your data science and statistics knowledge, you will\n",
    "learn when to use different kinds of tests.)\n",
    "\n",
    "In the *t*-test, we compare the size of the difference between our\n",
    "observed result and the null hypothesis, divided by what you would\n",
    "typically expect by chance (i.e., standard error):\n",
    "\n",
    "$$t=\\frac{result - null }{chance}$$\n",
    "\n",
    "Since our sample result is a sample mean ($\\\\bar{x}$), and we know the\n",
    "$$t = \\frac{\\bar{x}-H_0}{\\frac{SD}{\\sqrt{n}}}$$\n",
    "\n",
    "We can plug in our numbers easily:\n",
    "\n",
    "$$t = \\frac{\\bar{x}-H_0}{\\frac{SD}{\\sqrt{n}}} =  \\frac{2.234-0}{\\frac{2.073}{\\sqrt{100}}} = 10.8$$\n",
    " The test assesses how much the data disagree with the null (i.e., the\n",
    "effect; top of fraction) compared to what you would typically expect by\n",
    "chance (bottom of fraction). Thus, we can literally read the result as\n",
    "saying \"our effect was 10.8 times greater than you would typically\n",
    "expect by chance.\" That sounds pretty good for our effect and pretty bad\n",
    "for the null hypothesis.\n",
    "\n",
    "It is convenient that the *t*-test works this way. However, truth be\n",
    "told, the test statistic need not have *any* intuitive meaning. To get\n",
    "our *p*-value, the only thing we need to do is assess how rare our\n",
    "result would be if the null hypothesis was true. Thus, it doesn't really\n",
    "matter if we can interpret the *p*-value directly. We simply need to\n",
    "know where *t*-test results tend to be when the null is true, and then\n",
    "we can see how rare a score of 10.8 would be in that situation, giving\n",
    "us our *p*-value.\n",
    "\n",
    "This is an easy question to answer. Statisticians have mapped out the\n",
    "exact behavior of each test statistic when the null hypothesis is true\n",
    "(or as we often say, \"under the null\"). We know, for example, that if\n",
    "the null hypothesis is true, that the *t*-test will be close to zero\n",
    "(almost always within $$3 points of zero). So, what is our *p*-value? If\n",
    "the null were true, how often could we get *t*-test result as big as\n",
    "10.8?\n",
    "\n",
    "Using Python\n",
    "=======\n",
    "\n",
    "With a bit of programming, Python will do all of this work for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def t_one_sample(samp, mu = 0.0, alpha = 0.05):\n",
    "    '''Function for two-sided one-sample t test'''\n",
    "    t_stat = stats.ttest_1samp(samp, mu)\n",
    "    scale = np.std(samp)\n",
    "    loc = np.mean(samp)\n",
    "    ci = stats.t.cdf(alpha/2, len(samp), loc=mu, scale=scale)\n",
    "    print('Results of one-sample two-sided t test')\n",
    "    print('Mean         = %4.3f' % loc)\n",
    "    print('t-Statistic  = %4.3f' % t_stat[0])\n",
    "    print('p-value      < %4.3e' % t_stat[1])\n",
    "    print('On degrees of freedom = %4d' % (len(samp) - 1))\n",
    "    print('Confidence Intervals for alpha =' + str(alpha))\n",
    "    print('Lower =  %4.3f Upper = %4.3f' % (loc - ci, loc + ci))\n",
    "    \n",
    "t_one_sample(attitude)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key information is from this function is:\n",
    "`t statistic = 10.7, df = 99, p-value < 2.9e-18`. Notice that the *p*-value is displayed in scientific notation. `2.9e-18` is scientific notation:\n",
    "2.9 x 10<sup>-18</sup> and means the same as 0.0000000000000000029. This\n",
    "is clearly less than .05 so we can reject the null hypothesis and\n",
    "conclude that the positive attitude observed among our participants was\n",
    "not a statistical fluke but likely a real trend in the population.\n",
    "\n",
    "\n",
    "### For Illustration Purposes\n",
    "\n",
    "How did Statsmodels compute that *p*-value? I will illustrate.\n",
    "\n",
    "I start with a plot of all the *t*-test results (for sample size of 100)\n",
    "you would expect **if the null hypothesis was true.** We know this,\n",
    "thanks to mathematicians.\n",
    "![](img/unnamed-chunk-8-1.png)\n",
    "\n",
    "The bell curve above illustrates all the possible *t*-test results one\n",
    "would expect when the null is true and their respective probabilities.\n",
    "We see here that most results are within about +/- 3 points from zero.\n",
    "Where is our result? Let's add it to the plot.\n",
    "\n",
    "![](img/unnamed-chunk-9-1.png)\n",
    "\n",
    "As we see, our result is out among values that are very, very rare under\n",
    "the null hypothesis. It appears that our data disagree the null\n",
    "hypothesis. When the null is true, we should be getting *t*-test results\n",
    "down in the center of the bell curve (approximately ± 3), but we didn't.\n",
    "We were up at 10.8.\n",
    "\n",
    "To find the *p*-value, we simply ask what percentage of our *t*-curve is\n",
    "out that far. In other words, what proportion of the bell curve extends\n",
    "out beyond the red line? What is the area \"in the upper tail\"?\n",
    "\n",
    "We can compute the p-value as $1 - cdf$, for the t-statistic, where $cdf$ is the cumulative density function. The statsmodels `t.cdf()` function computes the cdf given the t-statistic and the degrees of freedom; $n − 1 = 100 − 1 = 99$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "1 - t.cdf(10.8, df = 99, loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is saying there is \"zero\" probability of getting a result this big if\n",
    "the null were true; i.e., *p* = 0. In reality, *p* values are never zero\n",
    "but can get infinitely small. In this case the a tiny number is rounded to 0.\n",
    "\n",
    "This is called a on-tailed *p*-value. We actually, however, need to\n",
    "double it. The reason we need to double it is that our null hypothesis\n",
    "was that *μ* = 0. That is, the null is false if our result is\n",
    "significantly *larger* than zero (a positive attitude) or significantly\n",
    "*smaller* than zero (a negative attitude). This is consistent with how\n",
    "we asked our question: \"do people have positive or negative attitudes?\"\n",
    "In other words, we did not test a directional prediction; we would be\n",
    "interested in \"finding\" something regardless of the direction of the\n",
    "effect. Since the *p*-value is the probability of getting an effect\n",
    "\"this large\" and we do not care about the direction, it actually exists\n",
    "on both sides of the distribution (a negative attitude would have given\n",
    "us a negative *t*-score):\n",
    "\n",
    "![](img/unnamed-chunk-11-1.png)\n",
    "\n",
    "Thus, we have to double our *p*-value. This is standard practice any\n",
    "time you would be willing to declare the result significant **regardless\n",
    "of the direction**. We call this a *two-tailed p-value*.\n",
    "\n",
    "If this explanation is confusing, you can also understand it a slightly\n",
    "different way: by testing *H*<sub>0</sub> : *μ* = 0, you are really\n",
    "asking whether *μ* &lt; 0 or whether *μ* &gt; 0. You are essentially\n",
    "asking two separate questions of the data. You need to double your\n",
    "*p*-value.\n",
    "\n",
    "This is almost always what you want. We almost always want to be able to\n",
    "declare a result significant if the effect is large, regardless of\n",
    "whether the direction of the result matches our intuition or not. For\n",
    "example, if an intervention to increase productivity backfires and\n",
    "decreases productivity, we want to know that just as much as we want to\n",
    "know if it works.\n",
    "\n",
    "Thus, we almost always double the *p*-value for this reason. It is true\n",
    "that it makes it a little harder to get a significant result (less than\n",
    ".05), but we can extract more meaning from the result. It's worth it.\n",
    "\n",
    "Note: our doubled *p*-value here is still essentially zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.0 * (1 - t.cdf(9.2, 100, loc=0, scale=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
